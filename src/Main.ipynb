{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "Compute dtype: float16\n",
      "Variable dtype: float32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from efficientnet.tfkeras import EfficientNetB0\n",
    "import math\n",
    "import random\n",
    "import cv2\n",
    "import skimage.io\n",
    "import glob\n",
    "import os\n",
    "import functools\n",
    "from albumentations import *\n",
    "from sklearn import model_selection, metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "from config import Config\n",
    "from manager import DataManager\n",
    "from util import get_optimizer\n",
    "from generator import get_dataset\n",
    "from model import NeuralNet, fit, predict\n",
    "\n",
    "\n",
    "#tf.config.set_visible_devices([], 'GPU')\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)\n",
    "print('Compute dtype: %s' % policy.compute_dtype)\n",
    "print('Variable dtype: %s' % policy.variable_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = DataManager.get_train_file()\n",
    "\n",
    "# dataset = get_dataset(\n",
    "#     dataframe=data, \n",
    "#     input_path=Config.input.path,\n",
    "#     batch_size=Config.train.batch_size,\n",
    "#     training=True,\n",
    "#     augment=True,\n",
    "#     buffer_size=1,\n",
    "#     cache=False,\n",
    "# )\n",
    "\n",
    "# for x,y in dataset.take(1):\n",
    "#     x = x.numpy()\n",
    "#     print(\"x shape =\", x.shape)\n",
    "\n",
    "# fig, axes = plt.subplots(1, Config.train.batch_size, figsize=(20, 20))\n",
    "\n",
    "# if Config.train.batch_size > 1:\n",
    "#     for i, ax in enumerate(axes.reshape(-1)):\n",
    "#         ax.imshow(x[i])\n",
    "#         ax.axis('off')\n",
    "# else:\n",
    "#     axes.imshow(x[0])\n",
    "#     axes.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4246 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> fitting with accumulated gradients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LR 0.0000300 : LOSS 0.483440: 100%|██████████| 4246/4246 [26:57<00:00,  2.63it/s]\n",
      "100%|██████████| 1062/1062 [03:10<00:00,  5.57it/s]\n",
      "  0%|          | 0/4246 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score = 0.7471641767024998\n",
      ">> fitting with accumulated gradients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LR 0.0000974 : LOSS 0.350585: 100%|██████████| 4246/4246 [27:01<00:00,  2.62it/s]  \n",
      "100%|██████████| 1062/1062 [01:26<00:00, 12.32it/s]\n",
      "  0%|          | 0/4246 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score = 0.7965650766411051\n",
      ">> fitting with accumulated gradients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LR 0.0001648 : LOSS 0.307151: 100%|██████████| 4246/4246 [33:13<00:00,  2.13it/s]  \n",
      "100%|██████████| 1062/1062 [01:15<00:00, 14.14it/s]\n",
      "  0%|          | 0/4246 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score = 0.7204601385235989\n",
      ">> fitting with accumulated gradients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LR 0.0002323 : LOSS 0.287511:  37%|███▋      | 1587/4246 [20:25<34:12,  1.30it/s]   \n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/alex/.virtualenvs/pca/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-3-4f5bf3d6cb2a>\", line 67, in <module>\n",
      "    fit(model, train_dataset, loss_fn, optimizer, accum_steps)\n",
      "  File \"/home/alex/Projects/kaggle/prostate-cancer-grade-assessment/src/model.py\", line 78, in fit\n",
      "    if (i+1) % accum_steps == 0:\n",
      "  File \"/home/alex/.virtualenvs/pca/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 767, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/home/alex/.virtualenvs/pca/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 801, in _call\n",
      "    results = self._stateful_fn(*args, **kwds)\n",
      "  File \"/home/alex/.virtualenvs/pca/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2811, in __call__\n",
      "    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n",
      "  File \"/home/alex/.virtualenvs/pca/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1838, in _filtered_call\n",
      "    cancellation_manager=cancellation_manager)\n",
      "  File \"/home/alex/.virtualenvs/pca/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1914, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager))\n",
      "  File \"/home/alex/.virtualenvs/pca/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 549, in call\n",
      "    ctx=ctx)\n",
      "  File \"/home/alex/.virtualenvs/pca/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\n",
      "    inputs, attrs, num_outputs)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alex/.virtualenvs/pca/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alex/.virtualenvs/pca/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1148, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/alex/.virtualenvs/pca/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/alex/.virtualenvs/pca/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/home/alex/.virtualenvs/pca/lib/python3.6/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "\n",
    "input_shape = Config.input.input_shape\n",
    "input_path = Config.input.path\n",
    "seed = Config.train.seed\n",
    "folds = Config.train.folds\n",
    "batch_size = Config.train.batch_size\n",
    "epochs = Config.train.epochs\n",
    "accum_steps = Config.train.accum_steps\n",
    "\n",
    "lr_steps_per_epoch=math.ceil((10616 * (1-1/Config.train.folds)) / Config.train.batch_size)\n",
    "lr_max=Config.train.learning_rate.max\n",
    "lr_min=Config.train.learning_rate.min\n",
    "lr_decay_epochs=Config.train.learning_rate.decay_epochs\n",
    "lr_warmup_epochs=Config.train.learning_rate.warmup_epochs\n",
    "lr_power=Config.train.learning_rate.power\n",
    "\n",
    "units=Config.model.units\n",
    "dropout=Config.model.dropout\n",
    "activation=Config.model.activation\n",
    "\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "optimizer = get_optimizer(\n",
    "    steps_per_epoch=lr_steps_per_epoch,\n",
    "    lr_max=lr_max,\n",
    "    lr_min=lr_min,\n",
    "    decay_epochs=lr_decay_epochs,\n",
    "    warmup_epochs=lr_warmup_epochs,\n",
    "    power=lr_power\n",
    ")\n",
    "optimizer = mixed_precision.LossScaleOptimizer(optimizer, loss_scale='dynamic')\n",
    "\n",
    "classes = np.where(data.data_provider == 'karolinska', 6, 0) + data.isup_grade.values\n",
    "skf = model_selection.StratifiedKFold(\n",
    "    folds, shuffle=True, random_state=seed).split(data.image_id, y=data.isup_grade)\n",
    "\n",
    "for fold_num, (train_idx, valid_idx) in enumerate(skf):\n",
    "\n",
    "    if fold_num == 0:\n",
    "        model = NeuralNet(\n",
    "            engine=EfficientNetB0, \n",
    "            input_shape=input_shape, \n",
    "            units=units,\n",
    "            dropout=dropout,\n",
    "            activation=activation,\n",
    "            weights='noisy-student')\n",
    "        model.build([None, *input_shape])\n",
    "        \n",
    "        train_dataset = get_dataset(\n",
    "            dataframe=data.iloc[train_idx], \n",
    "            input_path=input_path, \n",
    "            batch_size=batch_size,\n",
    "            training=True,\n",
    "            augment=True,\n",
    "            buffer_size=1024,\n",
    "            cache=False,\n",
    "        )\n",
    "        \n",
    "        valid_dataset = get_dataset(\n",
    "            dataframe=data.iloc[valid_idx], \n",
    "            input_path=input_path, \n",
    "            batch_size=batch_size,\n",
    "            training=False,\n",
    "            augment=False,\n",
    "            buffer_size=1,\n",
    "            cache=True,\n",
    "        )\n",
    "\n",
    "        best_score = float('-inf')\n",
    "        for epoch_num in range(epochs):\n",
    "            \n",
    "            fit(model, train_dataset, loss_fn, optimizer, accum_steps)\n",
    "\n",
    "            preds, trues = predict(model, valid_dataset)\n",
    "\n",
    "            if Config.infer.tta > 1:\n",
    "                preds = preds.reshape((-1, Config.infer.tta)).mean(-1)\n",
    "                trues = trues.reshape((-1, Config.infer.tta)).mean(-1)\n",
    "                \n",
    "            preds = np.round(preds, 0)\n",
    "            trues = np.round(trues, 0)\n",
    "            score = metrics.cohen_kappa_score(trues, preds, weights='quadratic')\n",
    "            print(\"\\nscore =\", score)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                model.save_weights(f'output/weights/model-{fold_num}-{epoch_num}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
